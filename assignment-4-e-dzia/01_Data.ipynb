{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import zipfile\n",
    "import gensim\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import tweepy as tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('raw.pickle', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    data = u.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'texts', 'val_ind', 'test_ind', 'train_ind'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data['texts']))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': array([1., 0., 0., 0., 0., 0., 0.])},\n",
       " {'label': array([0., 1., 0., 0., 0., 0., 0.])},\n",
       " {'label': array([0., 0., 1., 0., 0., 0., 0.])},\n",
       " {'label': array([0., 0., 0., 1., 0., 0., 0.])},\n",
       " {'label': array([0., 0., 0., 0., 1., 0., 0.])}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['info'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_text = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [np.argmax(el['label']) for el in data['info']]  # np.argmax\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['During the period of falling in love, each time that we met and especially when we had not met for a long time.',\n",
       " 'When I was involved in a traffic accident.',\n",
       " 'When I was driving home after  several days of hard work, there was a motorist ahead of me who was driving at 50 km/hour and refused, despite his low speeed to let me overtake.',\n",
       " 'When I lost the person who meant the most to me. ',\n",
       " \"The time I knocked a deer down - the sight of the animal's injuries and helplessness.  The realization that the animal was so badly hurt that it had to be put down, and when the animal screamed at the moment of death.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['texts']\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Word2vec: http://vectors.nlpl.eu/repository/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 623 ms, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with zipfile.ZipFile(\"18.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "    word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=False, unicode_errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said',\n",
       " 'also',\n",
       " 'would',\n",
       " 'one',\n",
       " 'first',\n",
       " 'two',\n",
       " 'year',\n",
       " \"n't\",\n",
       " 'percent',\n",
       " 'people']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.index2word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_texts(texts):\n",
    "    vectors = []\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text_vectors = []\n",
    "        for word in text:\n",
    "            word = word.lower()\n",
    "            try:\n",
    "                vec = word2vec_model[word]\n",
    "                text_vectors.append(vec)\n",
    "            except KeyError:\n",
    "                vec = None\n",
    "        if len(text_vectors) > 0:\n",
    "            vectors.append(np.mean(text_vectors, axis=0))\n",
    "        else:\n",
    "            vectors.append(np.array([0]*300))\n",
    "    return vectors\n",
    "\n",
    "vectors = vectorize_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open('vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(vectors, f)\n",
    "    \n",
    "with open('labels.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open('twitter_credentials.json', 'r') as secret_info:\n",
    "    twitter_cred = json.load(secret_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(twitter_cred[\"CONSUMER_KEY\"], twitter_cred[\"CONSUMER_SECRET\"])\n",
    "auth.set_access_token(twitter_cred[\"ACCESS_KEY\"], twitter_cred[\"ACCESS_SECRET\"])\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_tweets_by_search(search_term):\n",
    "    tweets = tw.Cursor(api.search,\n",
    "                  q=search_term,\n",
    "                  lang=\"en\").items(100)\n",
    "    return [tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last time a guest was wearing edm I got excited, until she was rude af and made me want to rage quit \\U0001f97a https://t.co/as1PvN8R0n',\n",
       " 'IM lecture marathon with IMD students ako starting tomorrow as make up classes because of holidays and earthquakes.… https://t.co/umIm2Ut6kC',\n",
       " \"I am so excited to be working with @deadbirds_net on my book trailers. I can't wait to see the finished versions!!… https://t.co/priucWTkNh\",\n",
       " '@Mrs_Steed19 a lot of my stuff is gender neutral too like grey and white! I’m so excited for you!',\n",
       " 'wish you were here']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joy_tweets = get_tweets_by_search('\"wish you\" OR excited -filter:retweets')\n",
    "joy_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IM SO TERRIFIED OF HOW SECRETIVE THEYRE BEING ABT S4 AS IF THERE’S HARDLY EVEN ANY MINOR THINGS THEY CAN SPOIL LIKE… https://t.co/0LBGmuRLpr',\n",
       " 'OMG THE DEMS MUST BE TERRIFIED! Extrapolated Results from FOX News Poll Show 70% of Americans (Reps and Inds) Are A… https://t.co/bZm0Ytszln',\n",
       " 'yesterday i orderd food from zomato for my husband and his frien, who were at my oher flat..That area is still deve… https://t.co/tCyKcRvrUB',\n",
       " 'OMG THE DEMS MUST BE TERRIFIED!  Extrapolated Results from FOX News Poll Show 70% of Americans (Reps and Inds) Are… https://t.co/bOjrsaGndN',\n",
       " 'NO WAIT MARTY IM SCARED I MIGHT NOT COME BACK']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fear_tweets = get_tweets_by_search('terrified OR scared -filter:retweets')\n",
    "fear_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if trump is sooo good the. why am i struggling to make it? huh? i legit work 40 hours a week and over half goes on… https://t.co/AO04YlIOYE',\n",
       " '@marklevinshow @realDonaldTrump And trump lied to voters to get elected in 2016 by PROMISING that Mex would pay for… https://t.co/j9mIDjTmf7',\n",
       " '@Meb7777i @eugenegu @IvankaTrump @SenWarren And... There are jobs out there &amp; thanks to Trump &amp; Ivanka, you can get… https://t.co/hmem7OPV4W',\n",
       " '#BREAKING!\\n\\n@realDonaldTrump says #Republicans should release their own taxes in impeachment probe | \\n https://t.co/6s1FMsuNFw #BreakingNews',\n",
       " '@SteveScalise @realDonaldTrump I can’t wait till Trump’s taxes come out😱😱😱that will be a movie in itself😱😱impeachme… https://t.co/TEkbv4kNiU']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anger_tweets = get_tweets_by_search('taxes trump -filter:retweets')\n",
    "anger_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Idk y'all but I already wrote my Christmas letter, have a look \\n\\n“Dear Santa,\\n\\nThis year I just want to lay down in… https://t.co/O0J7RmlVAN\",\n",
       " 'I woke up from a nightmare about my weight &amp; appearance and I’m. Really depressed now why does a stupid as dream make me want to cry',\n",
       " 'I’m actually so depressed all I do is cry and drink lucazade',\n",
       " 'This may sound mental but does anyone else just want to watch a tragedy like romantic tragedy to enjoy? like have a… https://t.co/SURS6SCzQM',\n",
       " 'If you girl can’t make you bawl, if you can’t cry around her, if she tell people that you bawl around her to make y… https://t.co/7INpfvTMEw']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadness_tweets = get_tweets_by_search('depressed cry OR \"not fine\" -filter:retweets')\n",
    "sadness_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Disgusting!! https://t.co/rK21orvVfH',\n",
       " \"@ushapadhee1996 You can't solve a problem by dodging it. Hope is idealistic not pragmatic. All have to face the pro… https://t.co/IPzMhOFlMZ\",\n",
       " \"I'm gonna start muting all accounts posting that vile tramp dancing around. I'm beyond sick of seeing her disgusting ass.\",\n",
       " '@PostOffice parcel to be delivered was left in general waste bin which was full of rubbish! So disgusting!',\n",
       " '@RAwamleh so disgusting']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disgust_tweets = get_tweets_by_search('disgust OR disgusting -filter:retweets')\n",
    "disgust_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@DarthBlount47 OC is a problem. Facts. Rudolph needs to not hold on to ball so long and make better reads/throws. B… https://t.co/yTzrcD4eD8',\n",
       " 'everytime i make an adult phone call i always end up embarassing myself.',\n",
       " 'theyre so embarassing i love them more than anything https://t.co/kP99dAnErd',\n",
       " \"don't even get near me if you feel embarassed to let people know that we're close enough to joke around 😌\",\n",
       " 'sit down gramps. this is more embarassing for you than you think it is  https://t.co/4lJcNdsmwP']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shame_tweets = get_tweets_by_search('embarassing OR \"feel embarassed\" -filter:retweets')\n",
    "shame_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I fucking hate that I feel guilty about talking loudly and excitedly about things or taking up space. I deserve to… https://t.co/SxmK88DTtX',\n",
       " '@p_nthabeleng_ @asandamaswazi 😂😂😂😂 why do I feel guilty 🙈🙈🏃🏃🏃🏃',\n",
       " '@pc_irrelevant Do I feel guilty and would I do it again. https://t.co/OIBQLtpyNy',\n",
       " \"@law83692622 @cheryl_english I'm cross eyed driving home headaches then most evenings feel guilty as I tell Dad how… https://t.co/2ZBcT2k7P9\",\n",
       " 'Never feel guilty about doing what is best for you \\n#MotivationMonday #wellness']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guilt_tweets = get_tweets_by_search('\"self blame\" OR \"feel guilty\" -filter:retweets')\n",
    "guilt_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "tweets.extend(joy_tweets)\n",
    "tweets.extend(fear_tweets)\n",
    "tweets.extend(anger_tweets)\n",
    "tweets.extend(sadness_tweets)\n",
    "tweets.extend(disgust_tweets)\n",
    "tweets.extend(shame_tweets)\n",
    "tweets.extend(guilt_tweets)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tweets = [0] * 100\n",
    "labels_tweets.extend([1] * 100)\n",
    "labels_tweets.extend([2] * 100)\n",
    "labels_tweets.extend([3] * 100)\n",
    "labels_tweets.extend([4] * 100)\n",
    "labels_tweets.extend([5] * 100)\n",
    "labels_tweets.extend([6] * 100)\n",
    "len(labels_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_vectors = vectorize_texts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tweets_vectors.pkl', 'wb') as f:\n",
    "#     pickle.dump(tweets_vectors, f)\n",
    "#     \n",
    "# with open('tweets_labels.pkl', 'wb') as f:\n",
    "#     pickle.dump(labels_tweets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
